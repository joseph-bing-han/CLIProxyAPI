package util

import (
	"testing"
)

// TestEstimateTokensForModel æµ‹è¯•ä¸åŒæ¨¡å‹çš„ token ä¼°ç®—
func TestEstimateTokensForModel(t *testing.T) {
	testCases := []struct {
		name         string
		model        string
		payload      []byte
		expectMinMax [2]int // [min, max] æœŸæœ›çš„ token èŒƒå›´
	}{
		{
			name:         "GPT-5 ç®€å•æ–‡æœ¬",
			model:        "gpt-5",
			payload:      []byte(`{"messages":[{"role":"user","content":"Hello, world!"}]}`),
			expectMinMax: [2]int{5, 30}, // å¤§çº¦ 10-20 tokens
		},
		{
			name:         "GPT-4o é•¿æ–‡æœ¬",
			model:        "gpt-4o",
			payload:      []byte(`{"messages":[{"role":"user","content":"This is a longer message that should contain more tokens for testing purposes."}]}`),
			expectMinMax: [2]int{10, 50},
		},
		{
			name:         "Claude Opus ç®€å•è¯·æ±‚",
			model:        "claude-opus-4",
			payload:      []byte(`{"model":"claude-opus-4","messages":[{"role":"user","content":"Hi"}]}`),
			expectMinMax: [2]int{3, 25},
		},
		{
			name:         "ç©º payload",
			model:        "gpt-5",
			payload:      []byte(``),
			expectMinMax: [2]int{0, 1}, // ç©ºè¾“å…¥åº”è¯¥è¿”å› 0 æˆ–æœ€å°å€¼ 1
		},
		{
			name:         "å¤æ‚ JSON ç»“æ„",
			model:        "gpt-5",
			payload:      []byte(`{"model":"gpt-5","messages":[{"role":"system","content":"You are helpful"},{"role":"user","content":"Question"},{"role":"assistant","content":"Answer"}],"temperature":0.7,"max_tokens":100}`),
			expectMinMax: [2]int{20, 60},
		},
		{
			name:         "GPT-3.5 æ¨¡å‹",
			model:        "gpt-3.5-turbo",
			payload:      []byte(`{"messages":[{"role":"user","content":"Test message"}]}`),
			expectMinMax: [2]int{5, 25},
		},
		{
			name:         "æœªçŸ¥æ¨¡å‹å›é€€",
			model:        "unknown-model",
			payload:      []byte(`{"messages":[{"role":"user","content":"Test"}]}`),
			expectMinMax: [2]int{3, 30},
		},
		{
			name:         "GPT-5-codex å˜ä½“",
			model:        "gpt-5-codex",
			payload:      []byte(`{"messages":[{"role":"user","content":"Write code"}]}`),
			expectMinMax: [2]int{5, 30},
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			result := EstimateTokensForModel(tc.model, tc.payload)

			// éªŒè¯ç»“æœä¸ä¸ºè´Ÿæ•°
			if result < 0 {
				t.Errorf("Token è®¡æ•°ä¸åº”ä¸ºè´Ÿæ•°ï¼Œå¾—åˆ°: %d", result)
			}

			// éªŒè¯ç»“æœåœ¨åˆç†èŒƒå›´å†…
			if result < tc.expectMinMax[0] || result > tc.expectMinMax[1] {
				t.Logf("è­¦å‘Š: Token è®¡æ•° %d è¶…å‡ºæœŸæœ›èŒƒå›´ [%d, %d]ï¼Œä½†è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„", 
					result, tc.expectMinMax[0], tc.expectMinMax[1])
			}

			t.Logf("æ¨¡å‹ %s çš„ payloadï¼ˆ%d bytesï¼‰ä¼°ç®—ä¸º %d tokens", 
				tc.model, len(tc.payload), result)
		})
	}
}

// TestEstimateTokensForModel_UTF8 æµ‹è¯• UTF-8 å­—ç¬¦å¤„ç†
func TestEstimateTokensForModel_UTF8(t *testing.T) {
	testCases := []struct {
		name    string
		model   string
		payload []byte
	}{
		{
			name:    "ä¸­æ–‡æ–‡æœ¬",
			model:   "gpt-5",
			payload: []byte(`{"messages":[{"role":"user","content":"ä½ å¥½ï¼Œä¸–ç•Œï¼è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"}]}`),
		},
		{
			name:    "æ—¥æ–‡æ–‡æœ¬",
			model:   "gpt-4o",
			payload: []byte(`{"messages":[{"role":"user","content":"ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ"}]}`),
		},
		{
			name:    "emoji",
			model:   "gpt-5",
			payload: []byte(`{"messages":[{"role":"user","content":"Hello ğŸ‘‹ World ğŸŒ"}]}`),
		},
		{
			name:    "æ··åˆè¯­è¨€",
			model:   "claude-opus-4",
			payload: []byte(`{"messages":[{"role":"user","content":"Hello ä½ å¥½ ã“ã‚“ã«ã¡ã¯"}]}`),
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			result := EstimateTokensForModel(tc.model, tc.payload)

			// UTF-8 å­—ç¬¦åº”è¯¥èƒ½æ­£ç¡®å¤„ç†
			if result <= 0 {
				t.Errorf("UTF-8 æ–‡æœ¬åº”è¯¥äº§ç”Ÿæ­£æ•°çš„ token è®¡æ•°ï¼Œå¾—åˆ°: %d", result)
			}

			t.Logf("UTF-8 payloadï¼ˆ%d bytesï¼‰ä¼°ç®—ä¸º %d tokens", len(tc.payload), result)
		})
	}
}

// TestEstimateTokensForModel_EdgeCases æµ‹è¯•è¾¹ç•Œæƒ…å†µ
func TestEstimateTokensForModel_EdgeCases(t *testing.T) {
	testCases := []struct {
		name    string
		model   string
		payload []byte
	}{
		{
			name:    "ä»…ç©ºæ ¼",
			model:   "gpt-5",
			payload: []byte("        "),
		},
		{
			name:    "ä»…æ¢è¡Œç¬¦",
			model:   "gpt-5",
			payload: []byte("\n\n\n"),
		},
		{
			name:    "è¶…é•¿æ–‡æœ¬",
			model:   "gpt-5",
			payload: []byte(`{"messages":[{"role":"user","content":"` + string(make([]byte, 10000)) + `"}]}`),
		},
		{
			name:    "æ— æ•ˆ JSON",
			model:   "gpt-5",
			payload: []byte(`{invalid json}`),
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// ä¸åº”è¯¥ panic
			defer func() {
				if r := recover(); r != nil {
					t.Errorf("EstimateTokensForModel panic: %v", r)
				}
			}()

			result := EstimateTokensForModel(tc.model, tc.payload)

			// ç»“æœåº”è¯¥æ˜¯éè´Ÿæ•°
			if result < 0 {
				t.Errorf("Token è®¡æ•°ä¸åº”ä¸ºè´Ÿæ•°ï¼Œå¾—åˆ°: %d", result)
			}

			t.Logf("è¾¹ç•Œæƒ…å†µ '%s' ä¼°ç®—ä¸º %d tokens", tc.name, result)
		})
	}
}

// TestEstimateTokensForModel_Consistency æµ‹è¯•ç›¸åŒè¾“å…¥çš„ä¸€è‡´æ€§
func TestEstimateTokensForModel_Consistency(t *testing.T) {
	model := "gpt-5"
	payload := []byte(`{"messages":[{"role":"user","content":"Test consistency"}]}`)

	// å¤šæ¬¡è°ƒç”¨åº”è¯¥è¿”å›ç›¸åŒç»“æœ
	firstResult := EstimateTokensForModel(model, payload)
	
	for i := 0; i < 10; i++ {
		result := EstimateTokensForModel(model, payload)
		if result != firstResult {
			t.Errorf("ç¬¬ %d æ¬¡è°ƒç”¨è¿”å›ä¸åŒç»“æœ: æœŸæœ› %d, å¾—åˆ° %d", i+1, firstResult, result)
		}
	}

	t.Logf("ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼Œæ‰€æœ‰è°ƒç”¨è¿”å› %d tokens", firstResult)
}

// BenchmarkEstimateTokensForModel æ€§èƒ½åŸºå‡†æµ‹è¯•
func BenchmarkEstimateTokensForModel(b *testing.B) {
	payload := []byte(`{"messages":[{"role":"user","content":"This is a test message for benchmarking token estimation performance"}]}`)
	
	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		EstimateTokensForModel("gpt-5", payload)
	}
}

// BenchmarkEstimateTokensForModel_Large å¤§ payload æ€§èƒ½æµ‹è¯•
func BenchmarkEstimateTokensForModel_Large(b *testing.B) {
	// åˆ›å»ºä¸€ä¸ªå¤§çš„ payload (çº¦ 100KB)
	largeContent := string(make([]byte, 100000))
	payload := []byte(`{"messages":[{"role":"user","content":"` + largeContent + `"}]}`)
	
	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		EstimateTokensForModel("gpt-5", payload)
	}
}

